{"cells":[{"cell_type":"code","execution_count":null,"id":"4c194463","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"4c194463","outputId":"39f6ff3d-e68e-4766-8313-69529f0e6810"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://download.pytorch.org/whl/cu118\n","Collecting torch==2.0.0+cu118\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.0%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","Collecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp310-cp310-manylinux_2_28_x86_64.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","Collecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp310-cp310-manylinux_2_28_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from torch==2.0.0+cu118) (3.17.0)\n","Collecting triton==2.0.0\n","  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","Collecting networkx\n","  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Requirement already satisfied: typing-extensions in /venv/main/lib/python3.10/site-packages (from torch==2.0.0+cu118) (4.12.2)\n","Collecting sympy\n","  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","Collecting jinja2\n","  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 KB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Collecting cmake\n","  Downloading https://download.pytorch.org/whl/cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","Collecting lit\n","  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 KB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","Collecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","Collecting pillow!=8.3.*,>=5.3.0\n","  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","Collecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","Requirement already satisfied: requests in /venv/main/lib/python3.10/site-packages (from torchvision) (2.32.3)\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","Requirement already satisfied: numpy in /venv/main/lib/python3.10/site-packages (from torchvision) (2.1.3)\n","Collecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.0%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.1%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.1%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.0%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.2%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.1%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.0%2Bcu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.2%2Bcu118-cp310-cp310-linux_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.1%2Bcu118-cp310-cp310-linux_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp310-cp310-linux_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch==2.0.0+cu118) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests->torchvision) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests->torchvision) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests->torchvision) (2025.1.31)\n","Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests->torchvision) (3.10)\n","Collecting mpmath<1.4,>=1.1.0\n","  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Building wheels for collected packages: lit\n","doneng wheel for lit (setup.py) ... \u001b[?25l\n","\u001b[?25h  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=90004 sha256=01111122fc17813b6745a9384eb18655bbc2cab7763c0b5eef13962aae11f86e\n","  Stored in directory: /root/.cache/pip/wheels/27/2c/b6/3ed2983b1b44fe0dea1bb35234b09f2c22fb8ebb308679c922\n","Successfully built lit\n","Installing collected packages: mpmath, lit, cmake, sympy, pillow, networkx, jinja2, triton, torch, torchvision, torchaudio\n","Successfully installed cmake-3.25.0 jinja2-3.1.4 lit-15.0.7 mpmath-1.3.0 networkx-3.3 pillow-11.0.0 sympy-1.13.3 torch-2.0.0+cu118 torchaudio-2.0.1+cu118 torchvision-0.15.1+cu118 triton-2.0.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","Installing collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.2+pt20cu118\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","Collecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","Collecting scipy\n","  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","Requirement already satisfied: numpy<2.5,>=1.23.5 in /venv/main/lib/python3.10/site-packages (from scipy->torch-sparse) (2.1.3)\n","Installing collected packages: scipy, torch-sparse\n","Successfully installed scipy-1.15.3 torch-sparse-0.6.18+pt20cu118\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","Collecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.3%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /venv/main/lib/python3.10/site-packages (from torch-cluster) (1.15.3)\n","Requirement already satisfied: numpy<2.5,>=1.23.5 in /venv/main/lib/python3.10/site-packages (from scipy->torch-cluster) (2.1.3)\n","Installing collected packages: torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cu118\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","Collecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (886 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.6/886.6 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","Installing collected packages: torch-spline-conv\n","Successfully installed torch-spline-conv-1.2.2+pt20cu118\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n","Requirement already satisfied: numpy in /venv/main/lib/python3.10/site-packages (from torch-geometric) (2.1.3)\n","Collecting aiohttp\n","  Downloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Collecting pyparsing\n","  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 KB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /venv/main/lib/python3.10/site-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: psutil>=5.8.0 in /venv/main/lib/python3.10/site-packages (from torch-geometric) (7.0.0)\n","Requirement already satisfied: tqdm in /venv/main/lib/python3.10/site-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: fsspec in /venv/main/lib/python3.10/site-packages (from torch-geometric) (2025.3.0)\n","Collecting propcache>=0.2.0\n","  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.3/287.3 KB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.8/219.8 KB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Collecting async-timeout<6.0,>=4.0\n","  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n","Collecting yarl<2.0,>=1.17.0\n","  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.9/333.9 KB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Collecting attrs>=17.3.0\n","  Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 KB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Collecting aiohappyeyeballs>=2.3.0\n","  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests->torch-geometric) (2025.1.31)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests->torch-geometric) (2.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests->torch-geometric) (3.4.1)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /venv/main/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n","Installing collected packages: pyparsing, propcache, multidict, frozenlist, attrs, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch-geometric\n","Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.3.0 frozenlist-1.6.0 multidict-6.4.3 propcache-0.3.1 pyparsing-3.2.3 torch-geometric-2.6.1 yarl-1.20.0\n","Collecting pandas\n","  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","Collecting matplotlib\n","  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n","Collecting pytz>=2020.1\n","  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n","Requirement already satisfied: numpy>=1.22.4 in /venv/main/lib/python3.10/site-packages (from pandas) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n","Collecting tzdata>=2022.7\n","  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 KB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Collecting threadpoolctl>=3.1.0\n","  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: scipy>=1.6.0 in /venv/main/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n","Collecting joblib>=1.2.0\n","  Downloading joblib-1.5.0-py3-none-any.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 KB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Collecting contourpy>=1.0.1\n","  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 KB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from matplotlib) (24.2)\n","Collecting fonttools>=4.22.0\n","  Using cached fonttools-4.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","Requirement already satisfied: pyparsing>=2.3.1 in /venv/main/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n","Collecting kiwisolver>=1.3.1\n","  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Collecting cycler>=0.10\n","  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n","Requirement already satisfied: pillow>=8 in /venv/main/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n","Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Installing collected packages: pytz, tzdata, threadpoolctl, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, pandas, matplotlib\n","Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.0 joblib-1.5.0 kiwisolver-1.4.8 matplotlib-3.10.3 pandas-2.2.3 pytz-2025.2 scikit-learn-1.6.1 threadpoolctl-3.6.0 tzdata-2025.2\n","Collecting numpy==1.24.4\n","  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.1.3\n","    Uninstalling numpy-2.1.3:\n","      Successfully uninstalled numpy-2.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.24.4\n"]}],"source":["# Install PyTorch Geometric & dependensinya untuk Colab\n","!pip install torch==2.0.0+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","!pip install torch-geometric\n","!pip install pandas scikit-learn matplotlib\n","# Downgrade NumPy ke versi stabil 1.x untuk kompatibilitas\n","!pip install numpy==1.24.4\n","\n"]},{"cell_type":"code","execution_count":null,"id":"jOW42u1Q-Scf","metadata":{"id":"jOW42u1Q-Scf"},"outputs":[],"source":["import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch_geometric.data import Dataset, Data\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","import ast\n"]},{"cell_type":"code","execution_count":null,"id":"b44c2d18","metadata":{"id":"b44c2d18"},"outputs":[],"source":["class CSVGraphDataset(Dataset):\n","    def __init__(self, csv_file, transform=None):\n","        self.df = pd.read_csv(csv_file)\n","        self.df[\"Node_Features\"] = self.df[\"Node_Features\"].apply(ast.literal_eval)\n","        self.df[\"Edge_Index\"] = self.df[\"Edge_Index\"].apply(ast.literal_eval)\n","        self.label_map = {\"tidak_estetik\": 0, \"estetik\": 1}\n","        self.transform = transform\n","        super().__init__()\n","\n","    def len(self):\n","        return len(self.df)\n","\n","    def get(self, idx):\n","        row = self.df.iloc[idx]\n","        x = torch.tensor(row[\"Node_Features\"], dtype=torch.float)\n","        edge_index = torch.tensor(row[\"Edge_Index\"], dtype=torch.long)\n","        if edge_index.shape[0] != 2:\n","            edge_index = edge_index.t().contiguous()\n","        y = torch.tensor(self.label_map[row[\"Category\"]], dtype=torch.long)\n","        data = Data(x=x, edge_index=edge_index, y=y)\n","        data.file_name = row[\"Filename\"]\n","        return self.transform(data) if self.transform else data\n"]},{"cell_type":"code","execution_count":null,"id":"Gvp04pbGAjtm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gvp04pbGAjtm","outputId":"c2e8b9fd-fee8-4a94-f942-60026941ca76"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gdown\n","  Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: requests[socks] in /venv/main/lib/python3.10/site-packages (from gdown) (2.32.3)\n","Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from gdown) (3.17.0)\n","Collecting beautifulsoup4\n","  Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.3/187.3 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /venv/main/lib/python3.10/site-packages (from gdown) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /venv/main/lib/python3.10/site-packages (from beautifulsoup4->gdown) (4.12.2)\n","Collecting soupsieve>1.2\n","  Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests[socks]->gdown) (2.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests[socks]->gdown) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests[socks]->gdown) (2025.1.31)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4.1)\n","Collecting PySocks!=1.5.7,>=1.5.6\n","  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n","Installing collected packages: soupsieve, PySocks, beautifulsoup4, gdown\n","Successfully installed PySocks-1.7.1 beautifulsoup4-4.13.4 gdown-5.2.0 soupsieve-2.7\n"]}],"source":["!pip install gdown\n"]},{"cell_type":"code","execution_count":null,"id":"b21f7623-232e-47b1-b4d1-e0423127480a","metadata":{"id":"b21f7623-232e-47b1-b4d1-e0423127480a","outputId":"9f6d9c7d-46f8-40d1-f32b-a0933c4e4e93"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1eRA8ZCgpODwOpAm3nsgg4_wzUCjcy9Vm\n","From (redirected): https://drive.google.com/uc?id=1eRA8ZCgpODwOpAm3nsgg4_wzUCjcy9Vm&confirm=t&uuid=236d122f-db3d-4ad8-adf9-0f561cc1e829\n","To: /workspace/graph_dataset_fresh_1.csv\n","100%|██████████| 7.90G/7.90G [01:47<00:00, 73.7MB/s]\n"]},{"data":{"text/plain":["'graph_dataset_fresh_1.csv'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import gdown\n","\n","# Ganti ini dengan ID file dari link berbagi Google Drive\n","file_id = '1eRA8ZCgpODwOpAm3nsgg4_wzUCjcy9Vm'\n","output = 'graph_dataset_fresh_1.csv'  # Ganti sesuai nama file yang diinginkan\n","gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=False)\n"]},{"cell_type":"code","execution_count":null,"id":"aF1B9e2MAOEi","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553},"id":"aF1B9e2MAOEi","outputId":"f2a3d2b0-cc2b-4d7e-b542-45c1789e76d7"},"outputs":[{"ename":"ParserError","evalue":"Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-20baa4ed32e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Hasil_Ekstraksi/graph_dataset_fresh.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Node_Features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."]}],"source":["import pandas as pd\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/Hasil_Ekstraksi/graph_dataset_fresh.csv\")\n","print(df.columns)\n","print(df.head(1)[\"Node_Features\"].values[0])\n"]},{"cell_type":"code","execution_count":null,"id":"eJc__IyLB1RI","metadata":{"id":"eJc__IyLB1RI"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv(\"/content/drive/MyDrive/Hasil_Ekstraksi/graph_dataset_fresh.csv\")\n","\n","# Cek baris yang tidak bisa dieval\n","import ast\n","\n","def is_valid_literal(x):\n","    try:\n","        ast.literal_eval(x)\n","        return True\n","    except:\n","        return False\n","\n","invalid_rows = df[~df[\"Node_Features\"].apply(is_valid_literal)]\n","print(\"Jumlah baris bermasalah:\", len(invalid_rows))\n","print(invalid_rows[[\"Filename\", \"Node_Features\"]].head())\n"]},{"cell_type":"code","execution_count":null,"id":"TmlLQLdMLzhi","metadata":{"id":"TmlLQLdMLzhi"},"outputs":[],"source":["print(invalid_rows[\"Filename\"].tolist())\n"]},{"cell_type":"code","execution_count":null,"id":"DUcS9brVMOWQ","metadata":{"id":"DUcS9brVMOWQ"},"outputs":[],"source":["import pandas as pd\n","\n","# Path file CSV lama\n","csv_path = \"/content/drive/MyDrive/Hasil_Ekstraksi/graph_dataset_fresh.csv\"\n","\n","# Daftar filename yang ingin dihapus\n","hapus_list = [\n","    '18650.jpg', '22236.jpg', '1524.jpg', '2663.jpg', '3660.jpg',\n","    '4873.jpg', '5406.jpg', '5847.jpg', '6737.jpg', '9981.jpg'\n","]\n","\n","# Baca CSV lama\n","df = pd.read_csv(csv_path)\n","\n","# Filter baris yang tidak termasuk file yang akan dihapus\n","df_bersih = df[~df[\"Filename\"].isin(hapus_list)]\n","\n","# Simpan ulang ke file asli\n","df_bersih.to_csv(csv_path, index=False)\n","\n","print(f\"✅ File berhasil diperbarui dan disimpan kembali ke:\\n{csv_path}\")\n","print(f\"📊 Total baris setelah dibersihkan: {len(df_bersih)}\")\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"Qbtbw7FbSN5V","executionInfo":{"status":"ok","timestamp":1747616444765,"user_tz":-420,"elapsed":19881,"user":{"displayName":"faiz fernanda","userId":"11922303303843277435"}},"outputId":"cdc64248-e81f-407b-b146-8b67789d81d7","colab":{"base_uri":"https://localhost:8080/"}},"id":"Qbtbw7FbSN5V","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"DcUmyFh1DtKf"},"id":"DcUmyFh1DtKf","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"2786bac7-04d0-43cd-8f0a-1035a2aac757","metadata":{"id":"2786bac7-04d0-43cd-8f0a-1035a2aac757"},"outputs":[],"source":["from torch_geometric.data import InMemoryDataset, Data\n","import torch\n","\n","# Praproses CSV menjadi daftar Data\n","data_list = []\n","for row in pd.read_csv(\"/content/drive/MyDrive/Hasil_Ekstraksi/graph_dataset_fresh.csv\", chunksize=10000):\n","    for i in range(len(row)):\n","        data = row_to_graph(row.iloc[i])\n","        data_list.append(data)\n","\n","torch.save(data_list, \"processed_graphs.pt\")\n"]},{"cell_type":"code","execution_count":null,"id":"8687849c","metadata":{"id":"8687849c","outputId":"f5a5db46-9d34-4fd0-a3ed-3dcdf7f66aaa"},"outputs":[{"name":"stderr","output_type":"stream","text":["Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7594749390c0>>\n","Traceback (most recent call last):\n","  File \"/venv/main/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n","    def _clean_thread_parent_frames(\n","KeyboardInterrupt: \n"]}],"source":["dataset = CSVGraphDataset(\"/workspace/graph_dataset_fresh_1.csv\")\n","\n","\n","train_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n","print(f\"Total graph: {len(dataset)}\")\n","\n"]},{"cell_type":"code","execution_count":null,"id":"0f1a97c0","metadata":{"id":"0f1a97c0"},"outputs":[],"source":["\n","\n","\n","sample = dataset[1881]\n","print(\"x shape:\", sample.x.shape)\n","print(\"edge_index shape:\", sample.edge_index.shape)\n","print(\"y:\", sample.y)\n"]},{"cell_type":"code","execution_count":null,"id":"EcILoFTZZM0K","metadata":{"id":"EcILoFTZZM0K"},"outputs":[],"source":["print(self.df.columns)  # akan tampil: Index(['Filename', 'Node_Features', ...])\n"]},{"cell_type":"code","execution_count":null,"id":"81c2b768","metadata":{"id":"81c2b768"},"outputs":[],"source":["# Cek label dari semua graph\n","from collections import Counter\n","\n","all_labels = [dataset[i].y.item() for i in range(len(dataset))]\n","print(\"🔢 Jumlah label per kelas:\")\n","print(Counter(all_labels))\n","\n","# Atau tampilkan semua:\n","print(\"📋 Semua label di dataset:\")\n","print(all_labels)\n"]},{"cell_type":"code","execution_count":null,"id":"8f00727d","metadata":{"id":"8f00727d"},"outputs":[],"source":["class GCNGraphClassifier(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = GCNConv(in_channels, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n","        self.lin = torch.nn.Linear(hidden_channels, out_channels)\n","\n","    def forward(self, x, edge_index, batch=None):\n","        x = self.conv1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.conv2(x, edge_index)\n","        x = F.relu(x)\n","        if batch is not None and x.size(0) > batch.max().item():\n","            x = global_mean_pool(x, batch)\n","            print(\"masuk\")\n","        else:\n","            x = x.mean(dim=0, keepdim=True)\n","        return self.lin(x)\n"]},{"cell_type":"code","execution_count":null,"id":"5Li8ozpull6G","metadata":{"id":"5Li8ozpull6G"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","\n","class GCNGraphClassifier(nn.Module):\n","    def __init__(self, input_dim=2800, hidden_dim=128, num_classes=2):\n","        super(GCNGraphClassifier, self).__init__()\n","\n","        self.gcn1 = GCNConv(input_dim, hidden_dim)\n","        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n","        self.dropout = nn.Dropout(p=0.3)\n","        self.classifier = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, x, edge_index, batch):\n","        x = self.gcn1(x, edge_index)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","\n","        x = self.gcn2(x, edge_index)\n","        x = F.relu(x)\n","\n","        x = global_mean_pool(x, batch)  # agregasi semua node dalam graf\n","        out = self.classifier(x)\n","        return out\n"]},{"cell_type":"code","execution_count":null,"id":"CNu9DJwudRa_","metadata":{"id":"CNu9DJwudRa_"},"outputs":[],"source":["# Pastikan class GCNGraphClassifier sudah didefinisikan sebelum ini\n","\n","# Ambil 1 sampel dari dataset untuk inisialisasi model\n","sample = dataset[0]\n","\n","# Inisialisasi model\n","model = GCNGraphClassifier(sample.num_node_features, 64, 2).to(device)\n","\n","# Optimizer dan loss\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","criterion = torch.nn.CrossEntropyLoss()\n"]},{"cell_type":"code","execution_count":null,"id":"Z0VPSSxvQm7Z","metadata":{"id":"Z0VPSSxvQm7Z"},"outputs":[],"source":["for epoch in range(1, 101):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch_idx, batch in enumerate(train_loader):\n","        batch = batch.to(device)\n","        optimizer.zero_grad()\n","        out = model(batch.x, batch.edge_index, batch.batch)\n","        loss = criterion(out, batch.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","        # 🔎 Tambahan: tampilkan output GCN per graf\n","        out_cpu = out.cpu()\n","        preds = out_cpu.argmax(dim=1)\n","        labels = batch.y.cpu()\n","\n","        # Ambil nama file kalau tersedia\n","        try:\n","            data_list = batch.to_data_list()\n","            file_names = [d.file_name if hasattr(d, 'file_name') else f\"G_{i}\" for i, d in enumerate(data_list)]\n","        except:\n","            file_names = [f\"G_{i}\" for i in range(len(labels))]\n","\n","        print(f\"\\n[Epoch {epoch} | Batch {batch_idx+1}]\")\n","        for i in range(len(preds)):\n","            print(f\"Graf ke-{i+1} ({file_names[i]}):\")\n","            print(f\"  Logit     : {out_cpu[i].tolist()}\")\n","            print(f\"  Prediksi  : {preds[i].item()}\")\n","            print(f\"  Label Asli: {labels[i].item()}\")\n","\n","    avg_loss = total_loss / len(train_loader)\n","    print(f\"\\n[Epoch {epoch}] Train Loss: {avg_loss:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"81a3fa96","metadata":{"id":"81a3fa96"},"outputs":[],"source":["import torch\n","from torch_geometric.loader import DataLoader\n","from torch.utils.data import random_split\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Setup device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Split dataset 80% train, 20% test\n","total = len(dataset)\n","train_size = int(0.8 * total)\n","test_size = total - train_size\n","train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32)\n","\n","# Inisialisasi model\n","sample = dataset[0]\n","model = GCNGraphClassifier(sample.num_node_features, 64, 2).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","train_losses = []\n","test_losses = []\n","eval_epochs = []\n","accs = []\n","precisions = []\n","recalls = []\n","f1s = []\n","\n","# Training\n","for epoch in range(1, 101):\n","    model.train()\n","    total_train_loss = 0\n","\n","    for batch in train_loader:\n","        batch = batch.to(device)\n","        optimizer.zero_grad()\n","        out = model(batch.x, batch.edge_index, batch.batch)\n","        loss = criterion(out, batch.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_train_loss += loss.item()\n","\n","    avg_train_loss = total_train_loss / len(train_loader)\n","\n","    # Hitung test loss\n","    model.eval()\n","    total_test_loss = 0\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            batch = batch.to(device)\n","            out = model(batch.x, batch.edge_index, batch.batch)\n","            loss = criterion(out, batch.y)\n","            total_test_loss += loss.item()\n","    avg_test_loss = total_test_loss / len(test_loader)\n","\n","    # Simpan loss setiap 10 epoch\n","    if epoch % 10 == 0:\n","        train_losses.append(avg_train_loss)\n","        test_losses.append(avg_test_loss)\n","\n","    # Evaluasi setiap 5 epoch\n","    if epoch % 5 == 0:\n","        model.eval()\n","        y_true = []\n","        y_pred = []\n","        misclassified_files = []\n","\n","        with torch.no_grad():\n","            for batch in test_loader:\n","                batch = batch.to(device)\n","                out = model(batch.x, batch.edge_index, batch.batch)\n","                preds = out.argmax(dim=1).cpu()\n","                labels = batch.y.cpu()\n","\n","                y_true.extend(labels.numpy())\n","                y_pred.extend(preds.numpy())\n","\n","                # ⬅️ Tracking file yang salah prediksi\n","                if hasattr(batch, 'file_name'):  # cek apakah file_name tersedia\n","                    for i in range(len(preds)):\n","                        if preds[i] != labels[i]:\n","                            misclassified_files.append(batch.file_name[i])\n","\n","\n","        acc = accuracy_score(y_true, y_pred)\n","        prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n","        rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n","        f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n","\n","        accs.append(acc)\n","        precisions.append(prec)\n","        recalls.append(rec)\n","        f1s.append(f1)\n","        eval_epochs.append(epoch)\n","\n","        print(f\"[Epoch {epoch}] Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f}\")\n","        print(f\"           Acc: {acc:.4f} | Prec: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n","        if misclassified_files:\n","            print(f\"  Salah prediksi ({len(misclassified_files)} graf):\")\n","            for name in misclassified_files[:5]:  # tampilkan 5 contoh saja\n","                print(f\"   - {name}\")\n","\n","\n","# Plot loss\n","plt.figure(figsize=(10, 5))\n","plt.plot(range(10, 101, 10), train_losses, label='Train Loss', marker='o')\n","plt.plot(range(10, 101, 10), test_losses, label='Test Loss', marker='s')\n","plt.title('Loss per 10 Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","# Plot metrik evaluasi\n","plt.figure(figsize=(10, 6))\n","plt.plot(eval_epochs, accs, label='Accuracy', marker='o')\n","plt.plot(eval_epochs, precisions, label='Precision', marker='s')\n","plt.plot(eval_epochs, recalls, label='Recall', marker='^')\n","plt.plot(eval_epochs, f1s, label='F1-score', marker='d')\n","plt.title('Evaluasi Model Setiap 5 Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Score')\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"0NBWfO5FPPp-","metadata":{"id":"0NBWfO5FPPp-"},"outputs":[],"source":["out = model(batch.x, batch.edge_index, batch.batch)  # output mentah\n","probs = torch.softmax(out, dim=1)                    # ubah jadi probabilitas\n","\n","# Ambil probabilitas kelas estetik (label = 1)\n","prob_estetik = probs[:, 1]  # shape [batch_size]\n","\n","for i, prob in enumerate(prob_estetik):\n","    print(f\"Graf ke-{i+1} → Estetik dengan kemungkinan {prob.item():.2%}\")\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
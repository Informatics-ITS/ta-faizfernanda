{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"X4Fr2OU6W_P9","outputId":"e9b0a73d-0aca-472b-f39b-ac086a6cc6c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing: samples/Tidak Estetik\\000_00198.jpg\n"]},{"ename":"RuntimeError","evalue":"Sizes of tensors must match except in dimension 1. Expected size 147 but got size 71 for tensor number 1 in the list.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 101\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m# Jalankan pipeline\u001b[39;00m\n\u001b[0;32m    100\u001b[0m dataset_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msamples/\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Path ke dataset yang berisi folder 'Estetik' dan 'Tidak Estetik'\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m save_graphs_to_hdf5(dataset_path)\n","Cell \u001b[1;32mIn[13], line 78\u001b[0m, in \u001b[0;36msave_graphs_to_hdf5\u001b[1;34m(dataset_path, hdf5_filename)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing: \u001b[39m\u001b[39m{\u001b[39;00mimage_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m image_tensor \u001b[39m=\u001b[39m load_image(image_path)\n\u001b[1;32m---> 78\u001b[0m features, W, H \u001b[39m=\u001b[39m extract_features(image_tensor, model)\n\u001b[0;32m     79\u001b[0m feature_graph \u001b[39m=\u001b[39m create_sparse_feature_graph(features, W, H)\n\u001b[0;32m     81\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[DEBUG] Image \u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mcategory\u001b[39m}\u001b[39;00m\u001b[39m): W=\u001b[39m\u001b[39m{\u001b[39;00mW\u001b[39m}\u001b[39;00m\u001b[39m, H=\u001b[39m\u001b[39m{\u001b[39;00mH\u001b[39m}\u001b[39;00m\u001b[39m, Nodes=\u001b[39m\u001b[39m{\u001b[39;00mW\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39mH\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","Cell \u001b[1;32mIn[13], line 40\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(image_tensor, model)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     38\u001b[0m     feature_maps \u001b[39m=\u001b[39m model(image_tensor)\n\u001b[1;32m---> 40\u001b[0m features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(feature_maps, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     41\u001b[0m W, H \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], features\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m]  \u001b[39m# Menggunakan ukuran asli dari CNN\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature shape: \u001b[39m\u001b[39m{\u001b[39;00mfeatures\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, W=\u001b[39m\u001b[39m{\u001b[39;00mW\u001b[39m}\u001b[39;00m\u001b[39m, H=\u001b[39m\u001b[39m{\u001b[39;00mH\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 147 but got size 71 for tensor number 1 in the list."]}],"source":["import torch\n","import timm\n","import torchvision.transforms as transforms\n","from PIL import Image, ImageOps\n","import networkx as nx\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import h5py\n","from torch_geometric.data import Data, DataLoader\n","\n","# Load model pre-trained dari TIMM dengan memastikan kita mengambil fitur sebelum FC\n","model = timm.create_model('inception_resnet_v2', pretrained=True, features_only=True)\n","model.eval()\n","\n","# Batch 1: Load Image & Preprocessing\n","def load_image(image_path, target_size=(299, 299)):\n","    \"\"\"Memuat gambar dengan mempertahankan aspek rasio dan menambahkan padding jika perlu.\"\"\"\n","    image = Image.open(image_path).convert(\"RGB\")\n","    image.thumbnail(target_size, Image.LANCZOS)\n","    delta_w = target_size[0] - image.size[0]\n","    delta_h = target_size[1] - image.size[1]\n","    padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n","    image = ImageOps.expand(image, padding, fill=(0, 0, 0))\n","\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","    ])\n","\n","    return transform(image).unsqueeze(0)\n","\n","# Batch 2: Extract Features\n","def extract_features(image_tensor, model):\n","    \"\"\"Mengekstrak fitur dari gambar sesuai ukuran hasil CNN tanpa memaksa ukuran tetap.\"\"\"\n","    model.eval()\n","    with torch.no_grad():\n","        feature_maps = model(image_tensor)\n","\n","    features = torch.cat(feature_maps, dim=1)\n","    W, H = features.shape[2], features.shape[3]  # Menggunakan ukuran asli dari CNN\n","    print(f\"Feature shape: {features.shape}, W={W}, H={H}\")\n","    return features.squeeze(0), W, H\n","\n","# Batch 3: Create Graph\n","def create_sparse_feature_graph(features, W, H):\n","    \"\"\"Membuat graph berbasis grid dengan mempertahankan struktur spasial asli sesuai hasil CNN.\"\"\"\n","    D = features.shape[0]\n","    feature_map = features.view(D, W * H).T  # Sesuai dengan aspek spasial dari CNN\n","    G = nx.Graph()\n","\n","    for i in range(W * H):\n","        G.add_node(i, feature=feature_map[i].tolist())\n","\n","    for x in range(W):\n","        for y in range(H):\n","            node_idx = x * H + y\n","            neighbors = [(x+dx, y+dy) for dx, dy in [(-1,0), (1,0), (0,-1), (0,1)]]\n","            for nx_, ny_ in neighbors:\n","                if 0 <= nx_ < W and 0 <= ny_ < H:\n","                    neighbor_idx = nx_ * H + ny_\n","                    G.add_edge(node_idx, neighbor_idx)\n","\n","    return G\n","\n","# Batch 4: Save Features & Graphs to HDF5\n","def save_graphs_to_hdf5(dataset_path, hdf5_filename=\"graph_dataset.hdf5\"):\n","    \"\"\"Menyimpan beberapa graph dari banyak gambar ke dalam HDF5 dengan label untuk klasifikasi GAT.\"\"\"\n","    with h5py.File(hdf5_filename, 'w') as hf:\n","        for label, category in enumerate([\"Tidak Estetik\", \"Estetik\"]):  # 0: Tidak Estetik, 1: Estetik\n","            category_path = os.path.join(dataset_path, category)\n","            for idx, filename in enumerate(os.listdir(category_path)):\n","                if filename.endswith(('.jpg', '.png', '.jpeg')):\n","                    image_path = os.path.join(category_path, filename)\n","                    print(f\"Processing: {image_path}\")\n","\n","                    image_tensor = load_image(image_path)\n","                    features, W, H = extract_features(image_tensor, model)\n","                    feature_graph = create_sparse_feature_graph(features, W, H)\n","\n","                    print(f\"[DEBUG] Image {idx} ({category}): W={W}, H={H}, Nodes={W * H}\")\n","\n","                    # Konversi graph ke format PyTorch Geometric\n","                    node_features = torch.tensor([feature_graph.nodes[n]['feature'] for n in feature_graph.nodes], dtype=torch.float)\n","                    edge_index = torch.tensor(list(feature_graph.edges)).t().contiguous()\n","                    graph_data = Data(x=node_features, edge_index=edge_index, y=torch.tensor([label], dtype=torch.long))\n","\n","                    # Simpan setiap graph dalam grup HDF5\n","                    grp_name = f\"graph_{category}_{idx}_size_{W}x{H}\"\n","                    grp = hf.create_group(grp_name)\n","                    grp.create_dataset(\"node_features\", data=np.array(graph_data.x, dtype=np.float32))\n","                    grp.create_dataset(\"edge_index\", data=np.array(graph_data.edge_index, dtype=np.int64))\n","                    grp.attrs[\"label\"] = label\n","                    grp.attrs[\"W\"] = W\n","                    grp.attrs[\"H\"] = H\n","\n","    print(f\"Graph dataset disimpan dalam {hdf5_filename}\")\n","\n","# Jalankan pipeline\n","dataset_path = 'samples/'  # Path ke dataset yang berisi folder 'Estetik' dan 'Tidak Estetik'\n","save_graphs_to_hdf5(dataset_path)"]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"eYpw6zgEXEnT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DdEkOK81W_P_","outputId":"56fa684e-4e80-4da5-8bd2-bb76bc764a62"},"outputs":[{"name":"stdout","output_type":"stream","text":["Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 000_00198.jpg, Original Size: (255, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Tidak Estetik_0_size_8x8\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Muhamad Faiz\\AppData\\Local\\Temp\\ipykernel_38900\\2781821444.py:100: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n","  grp.create_dataset(\"node_features\", data=np.array(graph_data.x, dtype=np.float32))\n","C:\\Users\\Muhamad Faiz\\AppData\\Local\\Temp\\ipykernel_38900\\2781821444.py:101: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n","  grp.create_dataset(\"edge_index\", data=np.array(graph_data.edge_index, dtype=np.int64))\n"]},{"name":"stdout","output_type":"stream","text":["Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 000_00398.jpg, Original Size: (255, 339), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Tidak Estetik_1_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 000_00413.jpg, Original Size: (255, 344), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Tidak Estetik_2_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 001_10033.jpg, Original Size: (382, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Tidak Estetik_3_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 002_00054.jpg, Original Size: (255, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Tidak Estetik_4_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 002_00301.jpg, Original Size: (255, 339), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Tidak Estetik_5_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 003_00136.jpg, Original Size: (454, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Tidak Estetik_6_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 003_00214.jpg, Original Size: (255, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Tidak Estetik_7_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 003_00337.jpg, Original Size: (255, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Tidak Estetik_8_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 004_00110.jpg, Original Size: (340, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Tidak Estetik_9_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 002_00103.jpg, Original Size: (383, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Estetik_0_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 002_10063.jpg, Original Size: (255, 290), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Estetik_1_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 004_00212.jpg, Original Size: (255, 382), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Estetik_2_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 024_00072.jpg, Original Size: (382, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Estetik_3_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 024_00394.jpg, Original Size: (381, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Estetik_4_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 025_00670.jpg, Original Size: (255, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Estetik_5_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 026_00276.jpg, Original Size: (340, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Estetik_6_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 029_00080.jpg, Original Size: (340, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Estetik_7_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 030_10003.jpg, Original Size: (414, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Estetik_8_size_8x8\n","Extracted Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Processing Image: 036_00229.jpg, Original Size: (492, 255), Features Shape: torch.Size([3200, 8, 8]), W=8, H=8\n","Saved: graph_Estetik_9_size_8x8\n","CSV dataset disimpan dalam graph_dataset.csv\n","Graph dataset disimpan dalam graph_dataset.hdf5\n"]}],"source":["import torch\n","import timm\n","import torchvision.transforms as transforms\n","from PIL import Image, ImageOps\n","import networkx as nx\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import h5py\n","import pandas as pd\n","from torch_geometric.data import Data, DataLoader\n","\n","# Load model pre-trained dari TIMM untuk ekstraksi fitur\n","model = timm.create_model('inception_resnet_v2', pretrained=True, features_only=True)\n","model.eval()\n","\n","# Fungsi memuat gambar dengan mempertahankan rasio aspek menggunakan padding\n","def load_image(image_path, target_size=(299, 299)):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    original_size = image.size  # Simpan ukuran asli gambar\n","\n","    # Menjaga rasio aspek dengan menambahkan padding hitam\n","    image.thumbnail(target_size, Image.LANCZOS)\n","    delta_w = target_size[0] - image.size[0]\n","    delta_h = target_size[1] - image.size[1]\n","    padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n","    image = ImageOps.expand(image, padding, fill=(0, 0, 0))\n","\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","    ])\n","\n","    return transform(image).unsqueeze(0), original_size\n","\n","# Fungsi ekstraksi fitur dari Inception-ResNet-v2 untuk digunakan dalam Graph Attention Network (GAT)\n","def extract_features(image_tensor, model):\n","    model.eval()\n","    with torch.no_grad():\n","        feature_maps = model(image_tensor)  # Mengambil semua layer fitur\n","\n","    # Gunakan resolusi spasial dari layer terakhir sebagai ukuran target\n","    target_W, target_H = feature_maps[-1].shape[2], feature_maps[-1].shape[3]\n","\n","    # Interpolasi semua feature maps ke ukuran dari layer terakhir\n","    resized_features = [torch.nn.functional.interpolate(f, size=(target_W, target_H), mode='bilinear', align_corners=False) for f in feature_maps]\n","\n","    # Gabungkan semua feature maps dalam dimensi kedalaman\n","    features = torch.cat(resized_features, dim=1).squeeze(0)  # Bentuk akhir: (D, W, H)\n","\n","    print(f\"Extracted Features Shape: {features.shape}, W={target_W}, H={target_H}\")\n","    return features, target_W, target_H\n","\n","# Fungsi membuat graph berbasis fitur dengan koneksi tetangga terdekat\n","def create_feature_graph(features, W, H):\n","    D = features.shape[0]\n","    feature_map = features.view(D, W * H).T.numpy()\n","    G = nx.Graph()\n","\n","    for i in range(W * H):\n","        G.add_node(i, feature=feature_map[i])\n","\n","    for x in range(W):\n","        for y in range(H):\n","            node_idx = x * H + y\n","            neighbors = [(x+dx, y+dy) for dx, dy in [(-1,0), (1,0), (0,-1), (0,1)]]\n","            for nx_, ny_ in neighbors:\n","                if 0 <= nx_ < W and 0 <= ny_ < H:\n","                    neighbor_idx = nx_ * H + ny_\n","                    G.add_edge(node_idx, neighbor_idx)\n","\n","    return G\n","\n","# Fungsi menyimpan dataset ke HDF5 dan CSV untuk digunakan dalam GNN (Graph Neural Networks)\n","def save_graphs_to_hdf5_and_csv(dataset_path, hdf5_filename=\"graph_dataset.hdf5\", csv_filename=\"graph_dataset.csv\"):\n","    csv_data = []\n","\n","    with h5py.File(hdf5_filename, 'w') as hf:\n","        for label, category in enumerate([\"Tidak Estetik\", \"Estetik\"]):\n","            category_path = os.path.join(dataset_path, category)\n","            for idx, filename in enumerate(os.listdir(category_path)):\n","                if filename.endswith(('.jpg', '.png', '.jpeg')):\n","                    image_path = os.path.join(category_path, filename)\n","                    image_tensor, original_size = load_image(image_path)\n","                    features, W, H = extract_features(image_tensor, model)\n","\n","                    print(f\"Processing Image: {filename}, Original Size: {original_size}, Features Shape: {features.shape}, W={W}, H={H}\")\n","\n","                    try:\n","                        feature_graph = create_feature_graph(features, W, H)\n","\n","                        # Konversi graph ke format PyTorch Geometric\n","                        node_features = torch.tensor([feature_graph.nodes[n]['feature'] for n in feature_graph.nodes], dtype=torch.float)\n","                        edge_index = torch.tensor(list(feature_graph.edges)).t().contiguous()\n","                        graph_data = Data(x=node_features, edge_index=edge_index, y=torch.tensor([label], dtype=torch.long))\n","\n","                        # Simpan ke HDF5\n","                        grp_name = f\"graph_{category}_{idx}_size_{W}x{H}\"\n","                        grp = hf.create_group(grp_name)\n","                        grp.create_dataset(\"node_features\", data=np.array(graph_data.x, dtype=np.float32))\n","                        grp.create_dataset(\"edge_index\", data=np.array(graph_data.edge_index, dtype=np.int64))\n","                        grp.attrs[\"label\"] = label\n","                        grp.attrs[\"W\"] = W\n","                        grp.attrs[\"H\"] = H\n","                        grp.attrs[\"Original_Size\"] = original_size\n","                        print(f\"Saved: {grp_name}\")\n","\n","                        # Simpan metadata dan struktur graph ke CSV\n","                        csv_data.append([\n","                            filename, category, W, H, original_size[0], original_size[1],\n","                            graph_data.x.flatten().tolist(),  # Flattened node features\n","                            graph_data.edge_index.numpy().tolist()  # Edge index\n","                        ])\n","\n","                    except Exception as e:\n","                        print(f\"Error processing {filename}: {e}\")\n","                        continue  # Lewati gambar yang menyebabkan error\n","\n","    # Simpan data ke CSV dengan kolom tambahan untuk graph\n","    df = pd.DataFrame(csv_data, columns=[\n","        \"Filename\", \"Category\", \"W\", \"H\", \"Original_Width\", \"Original_Height\", \"Node_Features\", \"Edge_Index\"\n","    ])\n","    df.to_csv(csv_filename, index=False)\n","    print(f\"CSV dataset disimpan dalam {csv_filename}\")\n","    print(f\"Graph dataset disimpan dalam {hdf5_filename}\")\n","\n","\n","# Jalankan pipeline\n","dataset_path = 'samples/'\n","save_graphs_to_hdf5_and_csv(dataset_path)"]},{"cell_type":"markdown","metadata":{"id":"NGnYAZvLW_P_"},"source":["test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJLqToQiW_QA","outputId":"c4b382e3-e541-4cc9-9cd1-0b7a0dfc2b3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['Filename', 'Category', 'W', 'H', 'Original_Width', 'Original_Height',\n","       'Node_Features', 'Edge_Index'],\n","      dtype='object')\n","        Filename       Category  W  H  Original_Width  Original_Height  \\\n","0  000_00198.jpg  Tidak Estetik  8  8             255              255   \n","1  000_00398.jpg  Tidak Estetik  8  8             255              339   \n","2  000_00413.jpg  Tidak Estetik  8  8             255              344   \n","3  001_10033.jpg  Tidak Estetik  8  8             382              255   \n","4  002_00054.jpg  Tidak Estetik  8  8             255              255   \n","\n","                                       Node_Features  \\\n","0  [0.7795566916465759, 0.7630141377449036, 0.272...   \n","1  [0.10722190886735916, 1.1118348836898804, 0.08...   \n","2  [0.10722190886735916, 1.1118348836898804, 0.08...   \n","3  [0.10722190886735916, 1.1118348836898804, 0.08...   \n","4  [0.8973767161369324, 0.49998754262924194, 0.17...   \n","\n","                                          Edge_Index  \n","0  [[0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7,...  \n","1  [[0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7,...  \n","2  [[0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7,...  \n","3  [[0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7,...  \n","4  [[0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7,...  \n"]}],"source":["import pandas as pd\n","\n","# Load CSV\n","df = pd.read_csv(\"graph_dataset.csv\")\n","\n","# Cek apakah semua kolom ada\n","print(df.columns)\n","\n","# Cek 5 data pertama\n","print(df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DoET7Q6JW_QA","outputId":"253a2590-c095-4f82-81f6-221c9c03eaa2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Graphs: 20\n","Sample Node Features Shape: torch.Size([204800])\n","Sample Edge Index Shape: torch.Size([112, 2])\n","Sample Label: tensor([0])\n"]}],"source":["import ast\n","from torch_geometric.utils import from_networkx\n","\n","# Fungsi memuat dataset dari CSV ke dalam PyTorch Geometric Dataset\n","class GraphDataset(Dataset):\n","    def __init__(self, csv_file):\n","        super(GraphDataset, self).__init__()\n","        self.data = pd.read_csv(csv_file)\n","\n","    def len(self):\n","        return len(self.data)\n","\n","    def get(self, idx):\n","        row = self.data.iloc[idx]\n","\n","        # Konversi fitur node dari string ke tensor\n","        node_features = torch.tensor(ast.literal_eval(row[\"Node_Features\"]), dtype=torch.float)\n","\n","        # Konversi edge index dari string ke tensor\n","        edge_index = torch.tensor(ast.literal_eval(row[\"Edge_Index\"]), dtype=torch.long).t().contiguous()\n","\n","        # Konversi kategori ke label 0/1\n","        label = torch.tensor([1 if row[\"Category\"] == \"Estetik\" else 0], dtype=torch.long)\n","\n","        # Membuat batch index agar bisa di-batch dalam GAT\n","        batch = torch.zeros(node_features.shape[0], dtype=torch.long)\n","\n","        return Data(x=node_features, edge_index=edge_index, y=label, batch=batch)\n","\n","# Load dataset\n","csv_filename = \"graph_dataset.csv\"\n","dataset = GraphDataset(csv_filename)\n","\n","# Debugging\n","print(f\"Total Graphs: {len(dataset)}\")\n","sample = dataset.get(0)\n","print(f\"Sample Node Features Shape: {sample.x.shape}\")\n","print(f\"Sample Edge Index Shape: {sample.edge_index.shape}\")\n","print(f\"Sample Label: {sample.y}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vj39vQjgW_QA"},"outputs":[],"source":["from torch_geometric.nn import GATConv, global_mean_pool\n","import torch.nn as nn\n","\n","class GATClassifier(torch.nn.Module):\n","    def __init__(self, in_channels=3200, hidden_channels=512, out_channels=2, heads=8):\n","        super(GATClassifier, self).__init__()\n","        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=0.6)\n","        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, dropout=0.6)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        x = F.elu(self.conv1(x, edge_index))\n","        x = self.conv2(x, edge_index)\n","\n","        # Gunakan mean pooling untuk mendapatkan satu output per graph\n","        x = global_mean_pool(x, batch)\n","\n","        return F.log_softmax(x, dim=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0d19gj9yW_QA","outputId":"aa7c64c1-e7b7-4bd3-a0e8-7c61a8b686c8"},"outputs":[{"ename":"IndexError","evalue":"tuple index out of range","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[18], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m---> 38\u001b[0m     loss \u001b[39m=\u001b[39m train()\n\u001b[0;32m     39\u001b[0m     acc \u001b[39m=\u001b[39m test()\n\u001b[0;32m     40\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{\u001b[39;00macc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","Cell \u001b[1;32mIn[18], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     10\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     12\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n","File \u001b[1;32mc:\\Users\\Muhamad Faiz\\Documents\\Faiz\\TA\\aesthetics_assessment_using_graphs-master\\aesthetics_assessment_using_graphs-master\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    709\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n","File \u001b[1;32mc:\\Users\\Muhamad Faiz\\Documents\\Faiz\\TA\\aesthetics_assessment_using_graphs-master\\aesthetics_assessment_using_graphs-master\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[1;32mc:\\Users\\Muhamad Faiz\\Documents\\Faiz\\TA\\aesthetics_assessment_using_graphs-master\\aesthetics_assessment_using_graphs-master\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[1;32mc:\\Users\\Muhamad Faiz\\Documents\\Faiz\\TA\\aesthetics_assessment_using_graphs-master\\aesthetics_assessment_using_graphs-master\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[1;32mc:\\Users\\Muhamad Faiz\\Documents\\Faiz\\TA\\aesthetics_assessment_using_graphs-master\\aesthetics_assessment_using_graphs-master\\.venv\\lib\\site-packages\\torch_geometric\\data\\dataset.py:291\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[39mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[39mpresent).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39mbool, will return a subset of the dataset at the specified indices.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, (\u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39minteger))\n\u001b[0;32m    288\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, Tensor) \u001b[39mand\u001b[39;00m idx\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m    289\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misscalar(idx))):\n\u001b[1;32m--> 291\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices()[idx])\n\u001b[0;32m    292\u001b[0m     data \u001b[39m=\u001b[39m data \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(data)\n\u001b[0;32m    293\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n","Cell \u001b[1;32mIn[15], line 28\u001b[0m, in \u001b[0;36mGraphDataset.get\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     25\u001b[0m label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m row[\u001b[39m\"\u001b[39m\u001b[39mCategory\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mEstetik\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m     27\u001b[0m \u001b[39m# Pastikan bahwa node_features memiliki ukuran (N, 3200)\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[39mif\u001b[39;00m node_features\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m!=\u001b[39m \u001b[39m3200\u001b[39m:\n\u001b[0;32m     29\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWarning: Fitur node dari \u001b[39m\u001b[39m{\u001b[39;00mrow[\u001b[39m'\u001b[39m\u001b[39mFilename\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m tidak sesuai! Ukuran: \u001b[39m\u001b[39m{\u001b[39;00mnode_features\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m Data(x\u001b[39m=\u001b[39mnode_features, edge_index\u001b[39m=\u001b[39medge_index, y\u001b[39m=\u001b[39mlabel)\n","\u001b[1;31mIndexError\u001b[0m: tuple index out of range"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Training Loop\n","def train():\n","    model.train()\n","    total_loss = 0\n","    for data in train_loader:\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        out = model(data)  # Sudah dikonversi dengan Mean Pooling agar ukuran tetap\n","        loss = criterion(out, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(train_loader)\n","\n","# Testing Loop\n","def test():\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in test_loader:\n","            data = data.to(device)\n","            out = model(data)\n","            pred = out.argmax(dim=1)\n","            correct += (pred == data.y).sum().item()\n","            total += data.y.size(0)\n","    return correct / total\n","\n","# Jalankan Training\n","epochs = 50\n","for epoch in range(epochs):\n","    loss = train()\n","    acc = test()\n","    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0lTAY8WcW_QA"},"outputs":[],"source":["def save_features_to_hdf5(folder_path, hdf5_filename=\"dataset_features.hdf5\"):\n","    \"\"\"Menyimpan fitur dari gambar ke dalam HDF5 tanpa reduksi fitur.\"\"\"\n","    with h5py.File(hdf5_filename, 'w') as hf:\n","        for idx, filename in enumerate(os.listdir(folder_path)):\n","            if filename.endswith(('.jpg', '.png', '.jpeg')):\n","                image_path = os.path.join(folder_path, filename)\n","                print(f\"Processing: {image_path}\")\n","\n","                image_tensor = load_image(image_path)\n","                features, W, H = extract_features(image_tensor, model)\n","\n","                grp = hf.create_group(f\"image_{idx}\")\n","                grp.create_dataset(\"features\", data=features.numpy())\n","                grp.attrs[\"W\"] = W\n","                grp.attrs[\"H\"] = H\n","\n","    print(f\"Dataset fitur disimpan dalam {hdf5_filename}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PiA9d-8rW_QA","outputId":"424d1457-5412-4d68-c483-838426816f4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing: samples/000_00198.jpg\n"]},{"ename":"RuntimeError","evalue":"Sizes of tensors must match except in dimension 1. Expected size 147 but got size 71 for tensor number 1 in the list.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Jalankan pipeline\u001b[39;00m\n\u001b[0;32m      2\u001b[0m folder_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msamples/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m save_features_to_hdf5(folder_path)\n","Cell \u001b[1;32mIn[27], line 10\u001b[0m, in \u001b[0;36msave_features_to_hdf5\u001b[1;34m(folder_path, hdf5_filename)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing: \u001b[39m\u001b[39m{\u001b[39;00mimage_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m image_tensor \u001b[39m=\u001b[39m load_image(image_path)\n\u001b[1;32m---> 10\u001b[0m features, W, H \u001b[39m=\u001b[39m extract_features(image_tensor, model)\n\u001b[0;32m     12\u001b[0m grp \u001b[39m=\u001b[39m hf\u001b[39m.\u001b[39mcreate_group(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimage_\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m grp\u001b[39m.\u001b[39mcreate_dataset(\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m, data\u001b[39m=\u001b[39mfeatures\u001b[39m.\u001b[39mnumpy())\n","Cell \u001b[1;32mIn[26], line 7\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(image_tensor, model)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m      5\u001b[0m     feature_maps \u001b[39m=\u001b[39m model(image_tensor)\n\u001b[1;32m----> 7\u001b[0m features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(feature_maps, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m W, H \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], features\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]  \u001b[39m# Ambil ukuran asli W x H dari CNN\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature shape: \u001b[39m\u001b[39m{\u001b[39;00mfeatures\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 147 but got size 71 for tensor number 1 in the list."]}],"source":["\n","# Jalankan pipeline\n","folder_path = 'samples/'\n","save_features_to_hdf5(folder_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G_pzcRLYW_QA","outputId":"a5cbf56c-30ef-453b-8848-2c4dd700cc94"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing: samples/000_00198.jpg\n","[DEBUG] Feature shape after resizing: torch.Size([1, 3200, 8, 8])\n","Processing: samples/000_00644.jpg\n","[DEBUG] Feature shape after resizing: torch.Size([1, 3200, 8, 8])\n","Processing: samples/000_10075.jpg\n","[DEBUG] Feature shape after resizing: torch.Size([1, 3200, 8, 8])\n","Processing: samples/001_00632.jpg\n","[DEBUG] Feature shape after resizing: torch.Size([1, 3200, 8, 8])\n","Processing: samples/004_00165.jpg\n","[DEBUG] Feature shape after resizing: torch.Size([1, 3200, 8, 8])\n","Dataset fitur dan graph disimpan dalam dataset_features.hdf5\n"]}],"source":["import torch\n","import timm\n","import torchvision.transforms as transforms\n","from PIL import Image, ImageOps\n","import networkx as nx\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import h5py\n","\n","# Load model pre-trained dari TIMM dengan memastikan kita mengambil fitur sebelum FC\n","model = timm.create_model('inception_resnet_v2', pretrained=True, features_only=True)\n","model.eval()\n","\n","# Batch 1: Load Image & Preprocessing\n","def load_image(image_path, target_size=(299, 299)):\n","    \"\"\"Memuat gambar dengan mempertahankan aspek rasio dan menambahkan padding jika perlu.\"\"\"\n","    image = Image.open(image_path).convert(\"RGB\")\n","    image.thumbnail(target_size, Image.LANCZOS)\n","    delta_w = target_size[0] - image.size[0]\n","    delta_h = target_size[1] - image.size[1]\n","    padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n","    image = ImageOps.expand(image, padding, fill=(0, 0, 0))\n","\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","    ])\n","\n","    return transform(image).unsqueeze(0)\n","\n","def extract_features(image_tensor, model, fixed_size=(8, 8)):\n","    \"\"\"Mengekstrak fitur dari gambar dan memastikan ukuran fitur tetap.\"\"\"\n","    model.eval()\n","    with torch.no_grad():\n","        feature_maps = model(image_tensor)\n","\n","    # **Interpolasi agar semua feature maps memiliki ukuran tetap**\n","    features = torch.cat([\n","        torch.nn.functional.interpolate(f, size=fixed_size, mode='bilinear')\n","        for f in feature_maps\n","    ], dim=1)\n","\n","    print(f\"[DEBUG] Feature shape after resizing: {features.shape}\")  # Debugging ukuran fitur\n","    return features.squeeze(0), fixed_size[0], fixed_size[1]\n","\n","\n","# Batch 3: Create Graph\n","def create_sparse_feature_graph(features, W, H):\n","    \"\"\"Membuat graph berbasis grid dengan mempertahankan struktur spasial asli.\"\"\"\n","    D = features.shape[0]\n","    feature_map = features.view(D, -1).T\n","    G = nx.Graph()\n","\n","    for i in range(W * H):\n","        G.add_node(i, feature=feature_map[i])\n","\n","    for x in range(W):\n","        for y in range(H):\n","            node_idx = x * H + y\n","            neighbors = [(x+dx, y+dy) for dx, dy in [(-1,0), (1,0), (0,-1), (0,1)]]\n","            for nx_, ny_ in neighbors:\n","                if 0 <= nx_ < W and 0 <= ny_ < H:\n","                    neighbor_idx = nx_ * H + ny_\n","                    G.add_edge(node_idx, neighbor_idx)\n","\n","    return G\n","\n","# Batch 4: Save Features & Graphs to HDF5\n","def save_features_and_graphs_to_hdf5(folder_path, hdf5_filename=\"dataset_features.hdf5\"):\n","    \"\"\"Menyimpan fitur dan graph ke dalam HDF5 tanpa mereduksi fitur.\"\"\"\n","    with h5py.File(hdf5_filename, 'w') as hf:\n","        for idx, filename in enumerate(os.listdir(folder_path)):\n","            if filename.endswith(('.jpg', '.png', '.jpeg')):\n","                image_path = os.path.join(folder_path, filename)\n","                print(f\"Processing: {image_path}\")\n","\n","                image_tensor = load_image(image_path)\n","                features, W, H = extract_features(image_tensor, model)\n","                feature_graph = create_sparse_feature_graph(features, W, H)\n","\n","                grp = hf.create_group(f\"image_{idx}\")\n","                grp.create_dataset(\"features\", data=features.numpy())\n","                grp.attrs[\"W\"] = W\n","                grp.attrs[\"H\"] = H\n","\n","                # Simpan adjacency matrix dari graph\n","                adj_matrix = nx.to_numpy_array(feature_graph)\n","                grp.create_dataset(\"adjacency_matrix\", data=adj_matrix)\n","\n","    print(f\"Dataset fitur dan graph disimpan dalam {hdf5_filename}\")\n","\n","# Jalankan pipeline\n","folder_path = 'samples/'\n","save_features_and_graphs_to_hdf5(folder_path)"]},{"cell_type":"markdown","metadata":{"id":"FhxJncubW_QB"},"source":["## TESTING CODE GNN\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YJpNv5jyW_QB","outputId":"b24d8b38-2d4a-45c0-be26-f0f28ce7f660"},"outputs":[{"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m features_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdatasets-master/git_web_ml/git_features.json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Read in edges\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m edges \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(edges_path)\n\u001b[0;32m      7\u001b[0m edges\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# renaming for StellarGraph compatibility\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# Read in features\u001b[39;00m\n","\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["edges_path = 'datasets-master/git_web_ml/git_edges.csv'\n","targets_path = 'datasets-master/git_web_ml/git_target.csv'\n","features_path = 'datasets-master/git_web_ml/git_features.json'\n","\n","# Read in edges\n","edges = pd.read_csv(edges_path)\n","edges.columns = ['source', 'target'] # renaming for StellarGraph compatibility\n","\n","# Read in features\n","with open(features_path) as json_data:\n","    features = json.load(json_data)\n","\n","max_feature = np.max([v for v_list in features.values() for v in v_list])\n","features_matrix = np.zeros(shape = (len(list(features.keys())), max_feature+1))\n","\n","i = 0\n","for k, vs in tqdm(features.items()):\n","    for v in vs:\n","        features_matrix[i, v] = 1\n","    i+=1\n","\n","node_features = pd.DataFrame(features_matrix, index = features.keys()) # into dataframe for StellarGraph\n","\n","# Read in targets\n","targets = pd.read_csv(targets_path)\n","targets.index = targets.id.astype(str)\n","targets = targets.loc[features.keys(), :]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XeNnNT-NW_QB","outputId":"a490fb4d-5cd7-4765-feba-8f8414134ee6"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 37700/37700 [00:00<00:00, 66851.11it/s]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import json\n","from tqdm import tqdm\n","import torch\n","from torch_geometric.data import Data\n","from sklearn import preprocessing\n","\n","edges_path = 'git_web_ml/musae_git_edges.csv'\n","targets_path = 'git_web_ml/musae_git_target.csv'\n","features_path = 'git_web_ml/musae_git_features.json'\n","\n","# Read in edges\n","edges = pd.read_csv(edges_path)\n","edges.columns = ['source', 'target'] # renaming for StellarGraph compatibility\n","\n","# Read in features\n","with open(features_path) as json_data:\n","    features = json.load(json_data)\n","\n","max_feature = np.max([v for v_list in features.values() for v in v_list])\n","features_matrix = np.zeros(shape = (len(list(features.keys())), max_feature+1))\n","\n","i = 0\n","for k, vs in tqdm(features.items()):\n","    for v in vs:\n","        features_matrix[i, v] = 1\n","    i+=1\n","\n","node_features = pd.DataFrame(features_matrix, index = features.keys()) # into dataframe for StellarGraph\n","\n","# Read in targets\n","targets = pd.read_csv(targets_path)\n","targets.index = targets.id.astype(str)\n","targets = targets.loc[features.keys(), :]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ui4dUAAKW_QB","outputId":"5013512c-94a6-491c-cd76-85f37e907a82"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data(x=[37700, 4005], edge_index=[2, 289003], y=[37700])\n","Jumlah node: 37700\n","Jumlah edge: 289003\n","Dimensi fitur: 4005\n","Jumlah kelas: 2\n"]}],"source":["# Konversi ke format PyG\n","import torch\n","from torch_geometric.data import Data\n","from sklearn import preprocessing\n","\n","# Konversi edge list menjadi tensor [2, num_edges]\n","edge_index = torch.tensor(edges.values.T, dtype=torch.long)\n","\n","# Konversi fitur ke tensor [num_nodes, num_features]\n","x = torch.tensor(node_features.values, dtype=torch.float)\n","\n","# Encode label ke angka (misalnya kolom \"ml_target\")\n","label_encoder = preprocessing.LabelEncoder()\n","y = torch.tensor(label_encoder.fit_transform(targets[\"ml_target\"]), dtype=torch.long)\n","\n","# Buat objek Data dari PyTorch Geometric\n","data = Data(x=x, edge_index=edge_index, y=y)\n","\n","# (Opsional) Cetak informasi graph\n","print(data)\n","print(f\"Jumlah node: {data.num_nodes}\")\n","print(f\"Jumlah edge: {data.num_edges}\")\n","print(f\"Dimensi fitur: {data.num_node_features}\")\n","print(f\"Jumlah kelas: {len(label_encoder.classes_)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DZJToFJ6W_QB","outputId":"f846c1be-3bce-4863-eaae-d036de7ebfa1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(200, 3) (200, 3) (37300, 3)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","train_pages, test_pages = train_test_split(targets, train_size=200)\n","val_pages, test_pages = train_test_split(test_pages, train_size=200)\n","print(train_pages.shape, val_pages.shape, test_pages.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4U7AutXW_QC"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","target_encoding = LabelEncoder()\n","\n","train_targets = torch.tensor(target_encoding.fit_transform(train_pages['ml_target']), dtype=torch.long)\n","val_targets = torch.tensor(target_encoding.transform(val_pages['ml_target']), dtype=torch.long)\n","test_targets = torch.tensor(target_encoding.transform(test_pages['ml_target']), dtype=torch.long)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-N36G1XW_QC"},"outputs":[],"source":["from torch_geometric.utils import add_self_loops, degree\n","\n","# 1. Tambahkan self-loop\n","edge_index, _ = add_self_loops(data.edge_index, num_nodes=data.num_nodes)\n","\n","# 2. Hitung derajat tiap node\n","row, col = edge_index\n","deg = degree(col, data.num_nodes, dtype=torch.float)\n","\n","# 3. Hitung D^(-1/2)\n","deg_inv_sqrt = deg.pow(-0.5)\n","deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n","\n","# 4. Hitung edge_weight ternormalisasi\n","edge_weight = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n","\n","# edge_index + edge_weight = adjacency ternormalisasi versi GCN\n","# Bisa dipakai langsung di GCNConv:\n","from torch_geometric.nn import GCNConv\n","\n","conv1 = GCNConv(in_channels=data.num_node_features, out_channels=16)\n","\n","x = conv1(data.x, edge_index, edge_weight=edge_weight)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MK6OIqxYW_QC"},"outputs":[],"source":["import torch\n","\n","# Buat boolean mask (default: semua False)\n","train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n","val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n","test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n","\n","# Isi dengan True untuk node yang digunakan\n","train_mask[train_pages.index.astype(int)] = True\n","val_mask[val_pages.index.astype(int)] = True\n","test_mask[test_pages.index.astype(int)] = True\n","\n","# Tambahkan ke objek data\n","data.train_mask = train_mask\n","data.val_mask = val_mask\n","data.test_mask = test_mask\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hioz0-q0W_QC"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"orig_nbformat":4,"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}
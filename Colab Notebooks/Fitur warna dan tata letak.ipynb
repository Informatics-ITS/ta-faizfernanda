{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPw7RWAn6+8Fq7DAhh3aVoR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3VwNW7S2tLZn","executionInfo":{"status":"ok","timestamp":1749633122639,"user_tz":-420,"elapsed":221296,"user":{"displayName":"faiz fernanda","userId":"11922303303843277435"}},"outputId":"eb195c88-dddd-462e-aedd-fb8086c6bdf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://download.pytorch.org/whl/cu118\n","Collecting torch==2.0.1\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m407.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.15.2\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==2.0.2\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp311-cp311-linux_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.14.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n","Collecting triton==2.0.0 (from torch==2.0.1)\n","  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.32.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (11.2.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n","Collecting lit (from triton==2.0.0->torch==2.0.1)\n","  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2025.4.26)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n","Building wheels for collected packages: lit\n","  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89990 sha256=484722281647130ea55f3c03bbd1b665d9fb8806616fe13394670cfc0c7ece49\n","  Stored in directory: /root/.cache/pip/wheels/fc/5d/45/34fe9945d5e45e261134e72284395be36c2d4828af38e2b0fe\n","Successfully built lit\n","Installing collected packages: lit, triton, torch, torchvision, torchaudio\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.21.0+cu124\n","    Uninstalling torchvision-0.21.0+cu124:\n","      Successfully uninstalled torchvision-0.21.0+cu124\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.6.0+cu124\n","    Uninstalling torchaudio-2.6.0+cu124:\n","      Successfully uninstalled torchaudio-2.6.0+cu124\n","Successfully installed lit-15.0.7 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (10.2 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.2+pt20cu118\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","Collecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n","Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.18+pt20cu118\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.6.1\n","Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.13.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.15.2+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.32.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->timm) (3.31.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->timm) (15.0.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->timm) (1.3.0)\n","Collecting numpy==1.26.4\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4\n"]}],"source":["# STEP 1: Install torch dan torchvision versi yang kompatibel (CUDA 11.8)\n","!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n","\n","# STEP 2: Install PyTorch Geometric dan dependensinya (harus urut)\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n","!pip install torch-geometric\n","\n","# STEP 3: Install library tambahan yang dibutuhkan\n","!pip install timm pillow matplotlib h5py pandas networkx\n","!pip install numpy==1.26.4\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1DgBeUrAtT3A","executionInfo":{"status":"ok","timestamp":1749633549795,"user_tz":-420,"elapsed":45947,"user":{"displayName":"faiz fernanda","userId":"11922303303843277435"}},"outputId":"fc688845-95e0-473d-8100-21f3a752cc44"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import torch\n","import timm\n","import torchvision.transforms as transforms\n","from PIL import Image, ImageOps\n","import networkx as nx\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import h5py\n","import pandas as pd\n","import gc\n","from torch_geometric.data import Data, DataLoader"],"metadata":{"id":"aZkuhpHNtWeb","executionInfo":{"status":"ok","timestamp":1749633612381,"user_tz":-420,"elapsed":25892,"user":{"displayName":"faiz fernanda","userId":"11922303303843277435"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f5028759-f2aa-461a-c96f-ee56fc7a9c38"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\n"]}]},{"cell_type":"code","source":["def load_image(image_path, target_size=(288, 288)):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    original_size = image.size\n","\n","    # Resize sambil mempertahankan rasio aspek\n","    image.thumbnail(target_size, Image.LANCZOS)\n","\n","    # Hitung padding yang diperlukan\n","    delta_w = target_size[0] - image.size[0]\n","    delta_h = target_size[1] - image.size[1]\n","\n","    # Hitung warna rata-rata dari gambar\n","    mean_color = tuple(np.array(image).reshape(-1, 3).mean(axis=0).astype(int))\n","\n","    # Tambahkan padding dengan warna rata-rata\n","    padding = (delta_w // 2, delta_h // 2, delta_w - delta_w // 2, delta_h - delta_h // 2)\n","    image = ImageOps.expand(image, padding, fill=mean_color)\n","\n","    return image, original_size"],"metadata":{"id":"wYCPmX7LtbzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_feature_graph(W, H):\n","    import networkx as nx\n","    G = nx.Graph()\n","    for i in range(W * H):\n","        G.add_node(i, feature=None)  # Placeholder, karena kita isi fitur nanti manual\n","\n","    for x in range(W):\n","        for y in range(H):\n","            node_idx = x * H + y\n","            neighbors = [(x+dx, y+dy) for dx, dy in [(-1,0), (1,0), (0,-1), (0,1)]]\n","            for nx_, ny_ in neighbors:\n","                if 0 <= nx_ < W and 0 <= ny_ < H:\n","                    neighbor_idx = nx_ * H + ny_\n","                    G.add_edge(node_idx, neighbor_idx)\n","    return G\n"],"metadata":{"id":"HykI-Fj2tn-F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.stats import skew  # untuk color moment ke-3\n","\n","def compute_color_moments(patch):\n","    moments = []\n","    for c in range(3):  # R, G, B\n","        channel = patch[:, :, c].flatten()\n","        moments.append(np.mean(channel))\n","        moments.append(np.std(channel))\n","        moments.append(skew(channel))\n","    return moments  # total 9 dimensi (3 momen Ã— 3 channel)"],"metadata":{"id":"-WegT1mtt0jz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_color_moments(pil_image, grid_size=(3, 3)):\n","    img_np = np.array(pil_image)  # Asumsi sudah resize + padding\n","    patch_h = img_np.shape[0] // grid_size[1]\n","    patch_w = img_np.shape[1] // grid_size[0]\n","\n","    color_moments = []\n","    for i in range(grid_size[1]):\n","        for j in range(grid_size[0]):\n","            patch = img_np[i*patch_h:(i+1)*patch_h, j*patch_w:(j+1)*patch_w, :]\n","            cm = compute_color_moments(patch)\n","            color_moments.append(cm)\n","    return np.array(color_moments)  # shape: [num_patches, 6]"],"metadata":{"id":"ZBMlBZaEt4DW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_graphs_with_color_moments(dataset_path,\n","                                   csv_filename=\"graph_datase_color_only.csv\",\n","                                   log_filename=\"log_gagal_color_only.txt\"):\n","\n","    csv_path = os.path.join('/content/drive/MyDrive/Hasil_Ekstraksi', csv_filename)\n","    log_path = os.path.join('/content/drive/MyDrive/Hasil_Ekstraksi', log_filename)\n","\n","    transform_tensor = transforms.Compose([transforms.ToTensor()])\n","    total_ok = 0\n","    total_fail = 0\n","\n","    if os.path.exists(csv_path):\n","        os.remove(csv_path)\n","    if os.path.exists(log_path):\n","        os.remove(log_path)\n","\n","    with open(log_path, 'w') as log_file:\n","        log_file.write(\"Log Gambar Gagal Diproses:\\n\")\n","\n","        with torch.no_grad():\n","            for label, category in enumerate([\"tidak_estetik\", \"estetik\"]):\n","                category_path = os.path.join(dataset_path, category)\n","                for filename in sorted(os.listdir(category_path)):\n","                    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n","                        continue\n","\n","                    try:\n","                        image_path = os.path.join(category_path, filename)\n","                        pil_image, original_size = load_image(image_path)\n","                        image_tensor = transform_tensor(pil_image).unsqueeze(0)\n","\n","                        # Gunakan ukuran grid tetap (misal 3x3)\n","                        W, H = 3, 3  # Atau sesuai kebutuhanmu\n","\n","                        color_moment_features = extract_color_moments(pil_image, grid_size=(W, H))\n","\n","                        # Fitur posisi + rasio aspek\n","                        positions = []\n","                        rasio_aspek = original_size[0] / original_size[1]\n","                        for idx in range(H * W):\n","                            y = idx // W\n","                            x = idx % W\n","                            x_norm = x / (W - 1) if W > 1 else 0.0\n","                            y_norm = y / (H - 1) if H > 1 else 0.0\n","                            positions.append([x_norm, y_norm, rasio_aspek])\n","\n","                        positions = np.array(positions)\n","                        combined = np.concatenate([color_moment_features, positions], axis=1)\n","\n","                        # Dummy edge untuk grid (grid 3x3 = 9 node)\n","                        feature_graph = create_feature_graph(W, H)  # kamu harus punya fungsi ini\n","                        edge_index = torch.tensor(list(feature_graph.edges)).t().contiguous()\n","\n","                        graph_data = Data(\n","                            x=torch.tensor(combined, dtype=torch.float),\n","                            edge_index=edge_index,\n","                            y=torch.tensor([label], dtype=torch.long)\n","                        )\n","\n","                        df_temp = pd.DataFrame([[filename, category, W, H, original_size[0], original_size[1],\n","                                                 graph_data.x.tolist(),\n","                                                 graph_data.edge_index.numpy().tolist()]],\n","                                               columns=['Filename', 'Category', 'W', 'H',\n","                                                        'Original_Width', 'Original_Height',\n","                                                        'Node_Features', 'Edge_Index'])\n","\n","                        mode = 'w' if total_ok == 0 else 'a'\n","                        df_temp.to_csv(csv_path, mode=mode, header=(total_ok == 0), index=False)\n","                        total_ok += 1\n","\n","                        print(f\"âœ”ï¸ {filename} | Fitur: {combined.shape[1]}\")\n","\n","                        del graph_data, color_moment_features, combined\n","                        gc.collect()\n","                        torch.cuda.empty_cache()\n","\n","                    except Exception as e:\n","                        print(f\"âš ï¸ Error processing {filename}: {e}\")\n","                        log_file.write(f\"{filename} ({category}) - {e}\\n\")\n","                        total_fail += 1\n","\n","    print(f\"\\nğŸ“ Dataset CSV baru disimpan di: {csv_path}\")\n","    print(f\"âœ… Total berhasil: {total_ok}\")\n","    print(f\"âŒ Total gagal: {total_fail}\")\n","    print(f\"ğŸ“ Log error: {log_path}\")\n"],"metadata":{"id":"xlbKisvmt6x-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_graphs_with_color_moments(dataset_path,\n","                                   csv_filename=\"graph_dataset_color_only.csv\",\n","                                   log_filename=\"log_gagal_color_only.txt\"):\n","\n","    csv_path = os.path.join('/content/drive/MyDrive/Hasil_Ekstraksi', csv_filename)\n","    log_path = os.path.join('/content/drive/MyDrive/Hasil_Ekstraksi', log_filename)\n","\n","    transform_tensor = transforms.Compose([transforms.ToTensor()])\n","    total_ok = 0\n","    total_fail = 0\n","\n","    if os.path.exists(csv_path):\n","        os.remove(csv_path)\n","    if os.path.exists(log_path):\n","        os.remove(log_path)\n","\n","    with open(log_path, 'w') as log_file:\n","        log_file.write(\"Log Gambar Gagal Diproses:\\n\")\n","\n","        with torch.no_grad():\n","            for label, category in enumerate([\"tidak_estetik\", \"estetik\"]):\n","                category_path = os.path.join(dataset_path, category)\n","                for filename in sorted(os.listdir(category_path)):\n","                    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n","                        continue\n","\n","                    try:\n","                        image_path = os.path.join(category_path, filename)\n","                        pil_image, original_size = load_image(image_path)\n","                        image_tensor = transform_tensor(pil_image).unsqueeze(0)\n","\n","                        # Ukuran grid 3x3\n","                        W, H = 3, 3\n","\n","                        # Ambil hanya fitur color moment\n","                        color_moment_features = extract_color_moments(pil_image, grid_size=(W, H))\n","\n","                        # Buat graph grid 3x3\n","                        feature_graph = create_feature_graph(W, H)  # fungsi ini harus sudah ada\n","                        edge_index = torch.tensor(list(feature_graph.edges)).t().contiguous()\n","\n","                        # Siapkan data graph\n","                        graph_data = Data(\n","                            x=torch.tensor(color_moment_features, dtype=torch.float),\n","                            edge_index=edge_index,\n","                            y=torch.tensor([label], dtype=torch.long)\n","                        )\n","\n","                        # Simpan ke CSV\n","                        df_temp = pd.DataFrame([[filename, category, W, H, original_size[0], original_size[1],\n","                                                 graph_data.x.tolist(),\n","                                                 graph_data.edge_index.numpy().tolist()]],\n","                                               columns=['Filename', 'Category', 'W', 'H',\n","                                                        'Original_Width', 'Original_Height',\n","                                                        'Node_Features', 'Edge_Index'])\n","\n","                        mode = 'w' if total_ok == 0 else 'a'\n","                        df_temp.to_csv(csv_path, mode=mode, header=(total_ok == 0), index=False)\n","                        total_ok += 1\n","\n","                        print(f\"âœ”ï¸ {filename} | Node features shape: {color_moment_features.shape}\")\n","\n","                        del graph_data, color_moment_features\n","                        gc.collect()\n","                        torch.cuda.empty_cache()\n","\n","                    except Exception as e:\n","                        print(f\"âš ï¸ Error processing {filename}: {e}\")\n","                        log_file.write(f\"{filename} ({category}) - {e}\\n\")\n","                        total_fail += 1\n","\n","    print(f\"\\nğŸ“ Dataset CSV disimpan di: {csv_path}\")\n","    print(f\"âœ… Total berhasil: {total_ok}\")\n","    print(f\"âŒ Total gagal: {total_fail}\")\n","    print(f\"ğŸ“ Log error: {log_path}\")\n"],"metadata":{"id":"Gmlr66IONSyb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_graphs_with_color_moments(dataset_path,\n","                                   csv_filename=\"graph_dataset_color_only.csv\",\n","                                   log_filename=\"log_gagal_color_only.txt\"):\n","\n","    csv_path = os.path.join('/content/drive/MyDrive/Hasil_Ekstraksi', csv_filename)\n","    log_path = os.path.join('/content/drive/MyDrive/Hasil_Ekstraksi', log_filename)\n","\n","    transform_tensor = transforms.Compose([transforms.ToTensor()])\n","\n","    # Muat data yang sudah berhasil (jika ada)\n","    processed_filenames = set()\n","    if os.path.exists(csv_path):\n","        try:\n","            existing_df = pd.read_csv(csv_path)\n","\n","            def is_valid_feature(val):\n","                try:\n","                    parsed = ast.literal_eval(val)\n","                    return isinstance(parsed, list) and len(parsed) > 0\n","                except:\n","                    return False\n","\n","            existing_df['Valid'] = existing_df['Node_Features'].apply(is_valid_feature)\n","            processed_filenames = set(existing_df[existing_df['Valid']]['Filename'].tolist())\n","\n","            failed_filenames = set(existing_df[~existing_df['Valid']]['Filename'].tolist())\n","            if failed_filenames:\n","                print(f\"ğŸ” Akan mencoba ulang file gagal: {sorted(failed_filenames)}\")\n","\n","        except Exception as e:\n","            print(f\"âš ï¸ Gagal membaca CSV lama: {e}. Mulai dari awal.\")\n","\n","    # Siapkan log error\n","    if os.path.exists(log_path):\n","        os.remove(log_path)\n","    with open(log_path, 'w') as log_file:\n","        log_file.write(\"Log Gambar Gagal Diproses:\\n\")\n","\n","        total_ok, total_fail = 0, 0\n","\n","        with torch.no_grad():\n","            for label, category in enumerate([\"tidak_estetik\", \"estetik\"]):\n","                category_path = os.path.join(dataset_path, category)\n","                for filename in sorted(os.listdir(category_path)):\n","                    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n","                        continue\n","\n","                    if filename in processed_filenames:\n","                        continue  # Lewati yang sudah benar-benar berhasil\n","\n","                    try:\n","                        image_path = os.path.join(category_path, filename)\n","                        pil_image, original_size = load_image(image_path)\n","                        image_tensor = transform_tensor(pil_image).unsqueeze(0)\n","\n","                        W, H = 3, 3  # grid 3x3\n","                        color_moment_features = extract_color_moments(pil_image, grid_size=(W, H))\n","\n","                        feature_graph = create_feature_graph(W, H)\n","                        edge_index = torch.tensor(list(feature_graph.edges)).t().contiguous()\n","\n","                        graph_data = Data(\n","                            x=torch.tensor(color_moment_features, dtype=torch.float),\n","                            edge_index=edge_index,\n","                            y=torch.tensor([label], dtype=torch.long)\n","                        )\n","\n","                        # Tambah ke CSV\n","                        df_temp = pd.DataFrame([[filename, category, W, H, original_size[0], original_size[1],\n","                                                 graph_data.x.tolist(),\n","                                                 graph_data.edge_index.numpy().tolist()]],\n","                                               columns=['Filename', 'Category', 'W', 'H',\n","                                                        'Original_Width', 'Original_Height',\n","                                                        'Node_Features', 'Edge_Index'])\n","\n","                        mode = 'a' if os.path.exists(csv_path) else 'w'\n","                        df_temp.to_csv(csv_path, mode=mode, header=not os.path.exists(csv_path), index=False)\n","\n","                        print(f\"âœ”ï¸ {filename} | Node features shape: {color_moment_features.shape}\")\n","                        total_ok += 1\n","\n","                        del graph_data, color_moment_features\n","                        gc.collect()\n","                        torch.cuda.empty_cache()\n","\n","                    except Exception as e:\n","                        print(f\"âš ï¸ Error processing {filename}: {e}\")\n","                        log_file.write(f\"{filename} ({category}) - {e}\\n\")\n","                        total_fail += 1\n","\n","        print(f\"\\nğŸ“ Dataset CSV disimpan di: {csv_path}\")\n","        print(f\"âœ… Total berhasil: {total_ok}\")\n","        print(f\"âŒ Total gagal: {total_fail}\")\n","        print(f\"ğŸ“ Log error: {log_path}\")"],"metadata":{"id":"8upc0nJu5eE5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Jalankan pipeline\n","dataset_path = '/content/drive/MyDrive/images_dataset_fix'\n","save_graphs_with_color_moments(dataset_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FvhIjLTtvDPh","outputId":"b6c28f1e-aa15-4461-9d3f-3d2209764a4d","executionInfo":{"status":"ok","timestamp":1749040173088,"user_tz":-420,"elapsed":10745,"user":{"displayName":"faiz fernanda","userId":"11922303303843277435"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ” Akan mencoba ulang file gagal: ['1524.jpg', '18650.jpg', '22236.jpg', '2663.jpg', '3660.jpg', '4873.jpg', '5406.jpg', '5847.jpg', '6737.jpg', '9981.jpg']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-50f0a13cd00f>:9: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n","  moments.append(skew(channel))\n"]},{"output_type":"stream","name":"stdout","text":["âœ”ï¸ 18650.jpg | Node features shape: (9, 9)\n","âœ”ï¸ 22236.jpg | Node features shape: (9, 9)\n","âœ”ï¸ 1524.jpg | Node features shape: (9, 9)\n","âœ”ï¸ 2663.jpg | Node features shape: (9, 9)\n","âœ”ï¸ 3660.jpg | Node features shape: (9, 9)\n","âœ”ï¸ 4873.jpg | Node features shape: (9, 9)\n","âœ”ï¸ 5406.jpg | Node features shape: (9, 9)\n","âœ”ï¸ 5847.jpg | Node features shape: (9, 9)\n","âœ”ï¸ 6737.jpg | Node features shape: (9, 9)\n","âœ”ï¸ 9981.jpg | Node features shape: (9, 9)\n","\n","ğŸ“ Dataset CSV disimpan di: /content/drive/MyDrive/Hasil_Ekstraksi/graph_dataset_color_only.csv\n","âœ… Total berhasil: 10\n","âŒ Total gagal: 0\n","ğŸ“ Log error: /content/drive/MyDrive/Hasil_Ekstraksi/log_gagal_color_only.txt\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","\n","# Path ke CSV hasil ekstraksi\n","csv_path = \"/content/drive/MyDrive/Hasil_Ekstraksi/graph_dataset_color_only.csv\"\n","\n","# Baca CSV\n","df = pd.read_csv(csv_path)\n","\n","# Fungsi untuk mengecek apakah Node_Features valid (list dan tidak kosong)\n","def is_valid_node_feature(val):\n","    try:\n","        parsed = ast.literal_eval(val)\n","        return isinstance(parsed, list) and len(parsed) > 0\n","    except:\n","        return False\n","\n","# Tambahkan kolom 'Valid'\n","df['Valid'] = df['Node_Features'].apply(is_valid_node_feature)\n","\n","# Hitung total valid dan tidak valid\n","total_valid = df['Valid'].sum()\n","total_invalid = len(df) - total_valid\n","\n","print(f\"âœ… Jumlah data dengan Node_Features valid: {total_valid}\")\n","print(f\"âŒ Jumlah data gagal/tidak valid: {total_invalid}\")\n","print(f\"ğŸ“Š Total baris di CSV: {len(df)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z7mbfLJu3SBZ","executionInfo":{"status":"ok","timestamp":1749040271132,"user_tz":-420,"elapsed":6879,"user":{"displayName":"faiz fernanda","userId":"11922303303843277435"}},"outputId":"fd12699b-3062-454b-b95f-7e5bbb1abd9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Jumlah data dengan Node_Features valid: 23990\n","âŒ Jumlah data gagal/tidak valid: 30\n","ğŸ“Š Total baris di CSV: 24020\n"]}]},{"cell_type":"code","source":["def reprocess_failed_graphs_from_list(dataset_path,\n","                                      failed_filenames,\n","                                      csv_filename=\"graph_datase_color_tata_letak.csv\"):\n","    import pandas as pd\n","    import numpy as np\n","    import torch\n","    import os\n","    import gc\n","    from torch_geometric.data import Data\n","    from torchvision import transforms\n","\n","    csv_path = os.path.join('/content/drive/MyDrive/Hasil_Ekstraksi', csv_filename)\n","\n","    print(f\"ğŸ“› Akan memproses ulang {len(failed_filenames)} file yang gagal sebelumnya.\")\n","\n","    # --- 1. Hapus entri lama dari CSV jika sudah ada ---\n","    if os.path.exists(csv_path):\n","        df = pd.read_csv(csv_path)\n","        df = df[~df[\"Filename\"].isin(failed_filenames)]\n","        df.to_csv(csv_path, index=False)\n","        print(\"ğŸ§¹ Entri lama yang gagal telah dibersihkan dari CSV.\")\n","\n","    # --- 2. Siapkan transformasi dan proses ulang hanya gambar yang gagal ---\n","    transform_tensor = transforms.Compose([transforms.ToTensor()])\n","    total_ok = 0\n","    total_fail = 0\n","\n","    with torch.no_grad():\n","        for label, category in enumerate([\"tidak_estetik\", \"estetik\"]):\n","            category_path = os.path.join(dataset_path, category)\n","            for filename in sorted(os.listdir(category_path)):\n","                if filename not in failed_filenames:\n","                    continue\n","                if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n","                    continue\n","\n","                try:\n","                    image_path = os.path.join(category_path, filename)\n","                    pil_image, original_size = load_image(image_path)\n","                    image_tensor = transform_tensor(pil_image).unsqueeze(0)\n","\n","                    W, H = 3, 3\n","                    color_moment_features = extract_color_moments(pil_image, grid_size=(W, H))\n","                    color_moment_features = np.nan_to_num(color_moment_features, nan=0.0, posinf=1e6, neginf=-1e6)\n","\n","                    # Posisi + rasio aspek\n","                    positions = []\n","                    rasio_aspek = original_size[0] / original_size[1]\n","                    for idx in range(H * W):\n","                        y = idx // W\n","                        x = idx % W\n","                        x_norm = x / (W - 1) if W > 1 else 0.0\n","                        y_norm = y / (H - 1) if H > 1 else 0.0\n","                        positions.append([x_norm, y_norm, rasio_aspek])\n","                    positions = np.array(positions)\n","\n","                    combined = np.concatenate([color_moment_features, positions], axis=1)\n","\n","                    # Graph dan Data\n","                    feature_graph = create_feature_graph(W, H)\n","                    edge_index = torch.tensor(list(feature_graph.edges)).t().contiguous()\n","                    graph_data = Data(\n","                        x=torch.tensor(combined, dtype=torch.float),\n","                        edge_index=edge_index,\n","                        y=torch.tensor([label], dtype=torch.long)\n","                    )\n","\n","                    df_temp = pd.DataFrame([[filename, category, W, H, original_size[0], original_size[1],\n","                                             graph_data.x.tolist(),\n","                                             graph_data.edge_index.numpy().tolist()]],\n","                                           columns=['Filename', 'Category', 'W', 'H',\n","                                                    'Original_Width', 'Original_Height',\n","                                                    'Node_Features', 'Edge_Index'])\n","\n","                    df_temp.to_csv(csv_path, mode='a', header=not os.path.exists(csv_path), index=False)\n","                    print(f\"âœ”ï¸ {filename} diproses ulang dan ditambahkan ke CSV.\")\n","                    total_ok += 1\n","\n","                    del graph_data, combined\n","                    gc.collect()\n","                    torch.cuda.empty_cache()\n","\n","                except Exception as e:\n","                    print(f\"âš ï¸ Gagal memproses ulang {filename}: {e}\")\n","                    total_fail += 1\n","\n","    print(f\"\\nğŸ“¦ Reprocess selesai. Sukses: {total_ok}, Gagal lagi: {total_fail}\")\n"],"metadata":{"id":"5w4rD8XwClbz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","\n","# Path ke file CSV kamu\n","csv_path = \"/content/drive/MyDrive/Hasil_Ekstraksi/color_only/csv_color_only.csv\"\n","\n","# Daftar gambar target\n","target_ids = ['1', '41', '49', '58', '6', '80', '111', '136', '747', '201']\n","target_filenames = [f\"{i}.jpg\" for i in target_ids]\n","\n","# Baca CSV\n","df = pd.read_csv(csv_path)\n","\n","# Filter berdasarkan nama file\n","filtered_df = df[df['Filename'].isin(target_filenames)].copy()\n","\n","# Fungsi untuk mencetak Node 0â€“2 dengan format sesuai permintaan\n","def print_first_3_nodes(row):\n","    try:\n","        node_features = ast.literal_eval(row['Node_Features'])\n","        print(f\"\\nğŸ“ {row['Filename']}\")\n","        for i in range(min(3, len(node_features))):\n","            print(f\"Node {i} : {node_features[i]}\")\n","    except Exception as e:\n","        print(f\"âŒ Error di {row['Filename']}: {e}\")\n","\n","# Jalankan fungsi untuk setiap baris\n","filtered_df.apply(print_first_3_nodes, axis=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zv2Ge6bLT8Oc","executionInfo":{"status":"ok","timestamp":1749529601266,"user_tz":-420,"elapsed":876,"user":{"displayName":"faiz fernanda","userId":"11922303303843277435"}},"outputId":"57402989-daf3-4d07-ad45-f2ef244d2d1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ“ 1.jpg\n","Node 0 : [186.61512756347656, 14.533888816833496, -3.4412951469421387, 167.55284118652344, 16.898588180541992, -0.5582130551338196, 159.79339599609375, 22.448741912841797, -0.6580144762992859]\n","Node 1 : [193.02734375, 7.811577320098877, 0.11124493926763535, 166.0377655029297, 37.342525482177734, -2.6271417140960693, 162.84060668945312, 35.506622314453125, -2.0490477085113525]\n","Node 2 : [194.60665893554688, 6.501161575317383, 0.779297947883606, 175.8079376220703, 16.364727020263672, 0.6768613457679749, 170.77615356445312, 17.75863265991211, 0.6945494413375854]\n","\n","ğŸ“ 111.jpg\n","Node 0 : [190.6194610595703, 42.467041015625, -0.6714568734169006, 155.77288818359375, 46.5402717590332, -0.3380005955696106, 80.43966674804688, 46.69710922241211, 0.5541598796844482]\n","Node 1 : [196.56793212890625, 26.705110549926758, -0.5855464935302734, 159.73968505859375, 30.452590942382812, -0.15674076974391937, 81.47797393798828, 31.234582901000977, 0.4375627636909485]\n","Node 2 : [159.41796875, 37.7646484375, -0.45629945397377014, 124.15375518798828, 35.39738464355469, -0.12064815312623978, 62.78841018676758, 25.864919662475586, 0.82243812084198]\n","\n","ğŸ“ 136.jpg\n","Node 0 : [171.0471954345703, 54.185997009277344, -1.124372124671936, 44.70583724975586, 35.66611862182617, 1.0261940956115723, 45.69162368774414, 37.04526901245117, 1.2158657312393188]\n","Node 1 : [172.92306518554688, 53.48643112182617, -1.1811027526855469, 44.48817443847656, 36.58091354370117, 1.1441398859024048, 42.048828125, 33.35048294067383, 1.0799219608306885]\n","Node 2 : [170.22634887695312, 50.82780456542969, -1.0702481269836426, 51.12087631225586, 41.372352600097656, 1.236539363861084, 44.505859375, 34.581966400146484, 1.2648471593856812]\n","\n","ğŸ“ 201.jpg\n","Node 0 : [182.57562255859375, 55.0058479309082, -0.1904791295528412, 135.7708282470703, 72.32743835449219, 0.5142822861671448, 107.35883331298828, 83.4305419921875, 0.790560781955719]\n","Node 1 : [182.30078125, 40.713687896728516, 0.18590158224105835, 117.97884368896484, 43.00242233276367, 0.8308582305908203, 73.20291137695312, 45.49102783203125, 1.340651512145996]\n","Node 2 : [200.92459106445312, 39.67668533325195, 0.07163356989622116, 132.78244018554688, 72.19744873046875, -0.0832044780254364, 118.27420043945312, 71.1949462890625, 0.3896135091781616]\n","\n","ğŸ“ 41.jpg\n","Node 0 : [181.90289306640625, 30.611984252929688, 0.44785431027412415, 147.74163818359375, 54.59189224243164, 0.46191713213920593, 141.25, 58.45640182495117, 0.4096177816390991]\n","Node 1 : [167.43121337890625, 60.80734634399414, -0.4669957160949707, 133.01443481445312, 85.10700225830078, -0.23205502331256866, 120.23751831054688, 90.88021850585938, -0.08845750987529755]\n","Node 2 : [164.65809631347656, 46.00962448120117, -1.1655759811401367, 119.48958587646484, 59.88113021850586, 0.20890668034553528, 108.84993743896484, 63.58190155029297, 0.2745051383972168]\n","\n","ğŸ“ 49.jpg\n","Node 0 : [127.34971618652344, 64.71019744873047, -0.5075324773788452, 115.01747131347656, 66.61782836914062, -0.46032777428627014, 102.04122924804688, 63.37138366699219, -0.27751269936561584]\n","Node 1 : [153.85797119140625, 71.60626220703125, -0.7233361005783081, 132.58377075195312, 73.31980895996094, -0.6792961359024048, 110.56727600097656, 64.00794982910156, -0.4395167827606201]\n","Node 2 : [110.84809112548828, 65.85636138916016, -0.35149526596069336, 92.85579681396484, 68.40194702148438, -0.1628534495830536, 81.32833862304688, 60.73599624633789, -0.06087877228856087]\n","\n","ğŸ“ 58.jpg\n","Node 0 : [49.39908981323242, 43.53634262084961, 0.04396333917975426, 39.66135025024414, 35.280853271484375, 0.2865920066833496, 25.12771224975586, 25.39610481262207, 1.5155380964279175]\n","Node 1 : [45.59299087524414, 43.444732666015625, -0.005011128727346659, 36.05989456176758, 33.97908401489258, -0.0066886586137115955, 22.05099868774414, 20.975860595703125, -0.007412563543766737]\n","Node 2 : [90.39420318603516, 63.422943115234375, 0.4512774646282196, 77.73003387451172, 60.48056411743164, 0.8222631812095642, 56.55685806274414, 55.12824249267578, 1.3655729293823242]\n","\n","ğŸ“ 6.jpg\n","Node 0 : [120.29524993896484, 35.969703674316406, -0.011412061750888824, 92.58365631103516, 28.561504364013672, 0.24210897088050842, 68.99674224853516, 22.755950927734375, 1.506742000579834]\n","Node 1 : [142.53668212890625, 66.84581756591797, -0.18925686180591583, 110.86089324951172, 55.12999725341797, -0.03005613386631012, 74.04513549804688, 34.600990295410156, 0.6021420955657959]\n","Node 2 : [133.36447143554688, 45.20547103881836, -0.1550772488117218, 104.05088806152344, 35.893272399902344, 0.09495223313570023, 62.93478775024414, 18.099821090698242, 1.3529794216156006]\n","\n","ğŸ“ 747.jpg\n","Node 0 : [168.6018829345703, 22.720190048217773, 0.030127016827464104, 160.2399139404297, 24.301971435546875, 0.014849194325506687, 157.60037231445312, 23.66082763671875, 0.01504145935177803]\n","Node 1 : [169.82931518554688, 23.86400032043457, 0.008622516877949238, 160.943359375, 24.971113204956055, 0.006650674156844616, 158.40646362304688, 24.433622360229492, 0.006645716726779938]\n","Node 2 : [167.9212188720703, 22.025836944580078, 0.027697566896677017, 158.93576049804688, 23.03221321105957, 0.02454734779894352, 156.39398193359375, 22.50557518005371, 0.028597040101885796]\n","\n","ğŸ“ 80.jpg\n","Node 0 : [63.39301300048828, 40.021114349365234, -0.34421586990356445, 39.60340881347656, 33.539085388183594, 0.0313614159822464, 28.64963150024414, 25.81736183166504, 0.4968448877334595]\n","Node 1 : [71.67860412597656, 32.8092041015625, -0.7039415836334229, 43.62239456176758, 28.147117614746094, -0.3042103350162506, 29.67892837524414, 21.61566734313965, -0.08043544739484787]\n","Node 2 : [77.58506774902344, 25.65411949157715, -0.8284651637077332, 47.20692443847656, 25.326021194458008, -0.3226647973060608, 31.78993034362793, 20.842548370361328, 0.055436477065086365]\n"]},{"output_type":"execute_result","data":{"text/plain":["10910    None\n","12134    None\n","14400    None\n","15122    None\n","17441    None\n","18328    None\n","19327    None\n","19548    None\n","21181    None\n","21770    None\n","dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10910</th>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>12134</th>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>14400</th>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>15122</th>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>17441</th>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>18328</th>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>19327</th>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>19548</th>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>21181</th>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>21770</th>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","import os\n","\n","# Path input dan output\n","csv_input_path = \"/content/drive/MyDrive/Hasil_Ekstraksi/graph_datase_color_tata_letak.csv\"\n","csv_output_dir = \"/content/drive/MyDrive/Hasil_Ekstraksi/color_only\"\n","csv_output_path = os.path.join(csv_output_dir, \"csv_color_only.csv\")\n","\n","# Pastikan folder tujuan ada\n","os.makedirs(csv_output_dir, exist_ok=True)\n","\n","# Baca CSV\n","df = pd.read_csv(csv_input_path)\n","\n","# Fungsi untuk membersihkan Node_Features\n","def remove_last_3_per_node(s):\n","    try:\n","        features = ast.literal_eval(s)\n","        cleaned = [node[:-3] for node in features]  # Hapus 3 nilai terakhir dari setiap node\n","        return cleaned\n","    except Exception as e:\n","        print(f\"âŒ Error parsing Node_Features: {e}\")\n","        return []\n","\n","# Terapkan fungsi ke kolom Node_Features\n","df[\"Node_Features\"] = df[\"Node_Features\"].apply(remove_last_3_per_node)\n","\n","# Simpan ke CSV baru\n","df.to_csv(csv_output_path, index=False)\n","print(f\"âœ… File disimpan di: {csv_output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3oXjsROBCmXx","executionInfo":{"status":"ok","timestamp":1749529492783,"user_tz":-420,"elapsed":14541,"user":{"displayName":"faiz fernanda","userId":"11922303303843277435"}},"outputId":"acdcee29-60d0-47ba-f3ba-31d4882aaa2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… File disimpan di: /content/drive/MyDrive/Hasil_Ekstraksi/color_only/csv_color_only.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import ast\n","import os\n","\n","# Path input dan output\n","csv_input_path = \"/content/drive/MyDrive/Hasil_Ekstraksi/graph_datase_color_tata_letak.csv\"\n","csv_output_dir = \"/content/drive/MyDrive/Hasil_Ekstraksi/tataletak\"\n","csv_output_path = os.path.join(csv_output_dir, \"tata_letak_only.csv\")\n","\n","# Pastikan folder tujuan ada\n","os.makedirs(csv_output_dir, exist_ok=True)\n","\n","# Baca CSV\n","df = pd.read_csv(csv_input_path)\n","\n","# Fungsi untuk menyimpan 3 nilai terakhir dari setiap node\n","def keep_last_3_per_node(s):\n","    try:\n","        features = ast.literal_eval(s)\n","        cleaned = [node[-3:] for node in features]  # Ambil 3 nilai terakhir dari setiap node\n","        return cleaned\n","    except Exception as e:\n","        print(f\"âŒ Error parsing Node_Features: {e}\")\n","        return []\n","\n","# Terapkan fungsi ke kolom Node_Features\n","df[\"Node_Features\"] = df[\"Node_Features\"].apply(keep_last_3_per_node)\n","\n","# Simpan ke CSV baru\n","df.to_csv(csv_output_path, index=False)\n","print(f\"âœ… File disimpan di: {csv_output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UosTVHQTTI5y","executionInfo":{"status":"ok","timestamp":1749633809227,"user_tz":-420,"elapsed":10955,"user":{"displayName":"faiz fernanda","userId":"11922303303843277435"}},"outputId":"d2ab00a9-4ca9-4976-d8d5-0346574028a9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… File disimpan di: /content/drive/MyDrive/Hasil_Ekstraksi/tataletak/tata_letak_only.csv\n"]}]}]}